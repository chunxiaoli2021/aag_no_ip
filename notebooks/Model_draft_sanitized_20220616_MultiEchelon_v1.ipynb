{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load package\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "import numpy as np\n",
    "import gurobipy as gp\n",
    "import time\n",
    "model_sanitized_path = 'C:/Users/52427/Documents/Cases/Case11_Baixiang/Baixiang_supply_chain_optimization/model_sanitized/'\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load input tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = model_sanitized_path + 'model_input_20220616_EN_v3.xlsx'\n",
    "xls = pd.ExcelFile(file_name)\n",
    "\n",
    "customers_df = pd.read_excel(xls, 'Input_CustomerList')\n",
    "\n",
    "sites_df = pd.read_excel(xls, 'Input_SiteList')\n",
    "\n",
    "products_df = pd.read_excel(xls, 'Input_ProductList')\n",
    "\n",
    "demand_df = pd.read_excel(xls, 'Input_CustomerDemand')\n",
    "\n",
    "trans_policies_df = pd.read_excel(xls, 'Input_TransportationPolicy')\n",
    "\n",
    "prod_policies_df = pd.read_excel(xls, 'Input_CapacityByLineByProduct')\n",
    "\n",
    "prod_line_policies_df = pd.read_excel(xls, 'Input_CapacityByLine')\n",
    "\n",
    "var_prod_cost_df = pd.read_excel(xls, 'Input_VariableProdCost')\n",
    "\n",
    "var_handling_cost_df = pd.read_excel(xls, 'Input_VariableHandlingCost')\n",
    "\n",
    "site_fixed_cost_df = pd.read_excel(xls, 'Input_SiteFixedCost')\n",
    "\n",
    "inv_df = pd.read_excel(xls, 'Input_InventoryPolicy')\n",
    "\n",
    "### load baseline data tables\n",
    "hist_outbound_trans_df = pd.read_excel(xls, sheet_name='Input_HistCustomerFlows')\n",
    "\n",
    "hist_inbound_trans_df = pd.read_excel(xls, sheet_name='Input_HistIntersiteFlows')\n",
    "\n",
    "hist_prod_df = pd.read_excel(xls, sheet_name='Input_HistProduction')\n",
    "\n",
    "xls.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# customers: 293\n",
      "# sites: 18\n",
      "# products: 61\n",
      "# customer-product combinations in demand table: 34115\n",
      "# customers in demand table: 293\n",
      "# products in demand table: 61\n",
      "# all lanes: 2718\n",
      "# origins in transportation table: 18\n",
      "# destinations in transportation table: 302\n",
      "# line-product combinations: 187\n",
      "# lines: 59\n",
      "# sites in factory fixed cost table: 18\n",
      "# products in factory variable production cost table: 61\n",
      "# dcs to customers: 34932\n",
      "# factories to dcs: 506\n",
      "# production combs: 1642\n"
     ]
    }
   ],
   "source": [
    "### print data info\n",
    "print('# customers:', customers_df.shape[0])\n",
    "print('# sites:', sites_df.shape[0])\n",
    "print('# products:', products_df.shape[0])\n",
    "print('# customer-product combinations in demand table:', demand_df.shape[0])\n",
    "print('# customers in demand table:', len(demand_df['CustomerName'].unique()))\n",
    "print('# products in demand table:', len(demand_df['ProductName'].unique()))\n",
    "print('# all lanes:', trans_policies_df.shape[0])\n",
    "print('# origins in transportation table:', trans_policies_df[['Origin']].drop_duplicates().shape[0])\n",
    "print('# destinations in transportation table:', trans_policies_df[['Destination']].drop_duplicates().shape[0])\n",
    "print('# line-product combinations:',prod_policies_df.shape[0])\n",
    "print('# lines:',prod_line_policies_df.shape[0])\n",
    "print('# sites in factory fixed cost table:', site_fixed_cost_df.shape[0])\n",
    "print('# products in factory variable production cost table:', len(var_prod_cost_df[['ProductName']].drop_duplicates()))\n",
    "\n",
    "### print baseline data info\n",
    "print('# dcs to customers:', hist_outbound_trans_df.shape[0])\n",
    "print('# factories to dcs:', hist_inbound_trans_df.shape[0])\n",
    "print('# production combs:', hist_prod_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create lists of basic model elements\n",
    "customers = [x for x in customers_df['CustomerName']]\n",
    "\n",
    "dcs = [x for x in sites_df['SiteName'][sites_df['SiteName'].str.contains('DC')]]\n",
    "\n",
    "factories = [x for x in sites_df['SiteName'][sites_df['SiteName'].str.contains('FAC')]]\n",
    "\n",
    "products = [x for x in products_df['ProductName']]\n",
    "\n",
    "months = range(1, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'FactoryName'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\52427\\Documents\\Cases\\Case11_Baixiang\\Baixiang_supply_chain_optimization\\model_sanitized\\Model_draft_sanitized_20220616.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/52427/Documents/Cases/Case11_Baixiang/Baixiang_supply_chain_optimization/model_sanitized/Model_draft_sanitized_20220616.ipynb#ch0000006?line=32'>33</a>\u001b[0m product_cubic \u001b[39m=\u001b[39m products_df\u001b[39m.\u001b[39mgroupby([\u001b[39m'\u001b[39m\u001b[39mProductName\u001b[39m\u001b[39m'\u001b[39m])[\u001b[39m'\u001b[39m\u001b[39mVolume\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmax()\u001b[39m.\u001b[39mto_dict()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/52427/Documents/Cases/Case11_Baixiang/Baixiang_supply_chain_optimization/model_sanitized/Model_draft_sanitized_20220616.ipynb#ch0000006?line=34'>35</a>\u001b[0m \u001b[39m### inventory turns\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/52427/Documents/Cases/Case11_Baixiang/Baixiang_supply_chain_optimization/model_sanitized/Model_draft_sanitized_20220616.ipynb#ch0000006?line=35'>36</a>\u001b[0m inv_turns \u001b[39m=\u001b[39m inv_df\u001b[39m.\u001b[39;49mgroupby([\u001b[39m'\u001b[39;49m\u001b[39mFactoryName\u001b[39;49m\u001b[39m'\u001b[39;49m])[\u001b[39m'\u001b[39m\u001b[39mInventoryTurns\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmax()\u001b[39m.\u001b[39mto_dict()\n",
      "File \u001b[1;32mc:\\Users\\52427\\.conda\\envs\\gurobienv\\lib\\site-packages\\pandas\\core\\frame.py:7712\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   7707\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m   7709\u001b[0m \u001b[39m# https://github.com/python/mypy/issues/7642\u001b[39;00m\n\u001b[0;32m   7710\u001b[0m \u001b[39m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[39;00m\n\u001b[0;32m   7711\u001b[0m \u001b[39m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[39;00m\n\u001b[1;32m-> 7712\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[0;32m   7713\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   7714\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[0;32m   7715\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   7716\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   7717\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[0;32m   7718\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m   7719\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[0;32m   7720\u001b[0m     squeeze\u001b[39m=\u001b[39;49msqueeze,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   7721\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m   7722\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[0;32m   7723\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\52427\\.conda\\envs\\gurobienv\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:882\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgroupby\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgrouper\u001b[39;00m \u001b[39mimport\u001b[39;00m get_grouper\n\u001b[1;32m--> 882\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[0;32m    883\u001b[0m         obj,\n\u001b[0;32m    884\u001b[0m         keys,\n\u001b[0;32m    885\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    886\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m    887\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    888\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m    889\u001b[0m         mutated\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmutated,\n\u001b[0;32m    890\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[0;32m    893\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[0;32m    894\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[1;32mc:\\Users\\52427\\.conda\\envs\\gurobienv\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py:882\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    880\u001b[0m         in_axis, level, gpr \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, gpr, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 882\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m    883\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(gpr, Grouper) \u001b[39mand\u001b[39;00m gpr\u001b[39m.\u001b[39mkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[39m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     exclusions\u001b[39m.\u001b[39madd(gpr\u001b[39m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'FactoryName'"
     ]
    }
   ],
   "source": [
    "### customer demand\n",
    "cust_demand = demand_df.groupby(['CustomerName', 'ProductName', 'Period'])['CustomerDemand'].sum().to_dict()\n",
    "\n",
    "### production capacity\n",
    "line_product_rate = prod_policies_df.groupby(['FactoryName', 'ProductLine', 'ProductName'])['MachineHoursPerUnit'].sum().to_dict()\n",
    "\n",
    "line_capacity_cap = prod_line_policies_df.groupby(['FactoryName', 'ProductLine'])['MachineHourCapacity'].sum().to_dict()\n",
    "\n",
    "line_product_dict = prod_policies_df.groupby(['FactoryName','ProductLine'])['ProductName'].apply(list).to_dict()\n",
    "\n",
    "### factory-attached warehouse storage capacity\n",
    "site_storage_cap = sites_df.groupby(['SiteName'])['StorageCapacity'].max().to_dict()\n",
    "\n",
    "### factory-attached warehouse handling capacity\n",
    "site_handling_cap = sites_df.groupby(['SiteName'])['HandlingCapacity'].max().to_dict()\n",
    "\n",
    "### factory variable production cost\n",
    "var_prod_cost = var_prod_cost_df.groupby(['FactoryName', 'ProductName'])['VariableCost'].sum().to_dict()\n",
    "\n",
    "### dc variable handling cost \n",
    "var_handling_cost = var_handling_cost_df.groupby(['SiteName'])['VariableCost'].sum().to_dict()\n",
    "\n",
    "### factory fixed cost\n",
    "site_fixed_cost = site_fixed_cost_df.groupby(['SiteName'])['FixedOperatingCost'].sum().to_dict()\n",
    "\n",
    "### transportation cost\n",
    "transp_cost = trans_policies_df.groupby(['Origin', 'Destination'])['Price'].max().to_dict()\n",
    "\n",
    "### transportation distance\n",
    "transp_dist = trans_policies_df.groupby(['Origin', 'Destination'])['Distance'].max().to_dict()\n",
    "\n",
    "### unit product cubic meters\n",
    "product_cubic = products_df.groupby(['ProductName'])['Volume'].max().to_dict()\n",
    "\n",
    "### inventory turns\n",
    "inv_turns = inv_df.groupby(['FactoryName'])['InventoryTurns'].max().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### historical factory-to-customer flows\n",
    "hist_fc_flows = hist_outbound_trans_df.groupby(\n",
    "    ['Origin', 'Destination', 'ProductName', 'Period'])['HistoricalShipment'].sum().to_dict()\n",
    "\n",
    "### historical inter-factory flows\n",
    "hist_ff_flows = hist_inbound_trans_df.groupby(\n",
    "    ['Origin', 'Destination', 'ProductName', 'Period'])['HistoricalShipment'].sum().to_dict()\n",
    "\n",
    "### historical production\n",
    "hist_prod_flows = hist_prod_df.groupby(\n",
    "    ['FactoryName', 'ProductLine', 'ProductName', 'Period'])['HistoricalProduction'].sum().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generate index sets\n",
    "ss_lanes = gp.tuplelist([(o, d, p, m) for o in factories for d in dcs for p in products for m in months]) \n",
    "\n",
    "sc_lanes = gp.tuplelist([(o, d, p, m) for o in dcs for (d, p, m) in cust_demand]) \n",
    "\n",
    "prod_policies_month_df = pd.merge(prod_policies_df[['FactoryName', 'ProductLine', 'ProductName']].assign(temp=1), \n",
    "                                  pd.DataFrame(months, columns =['Period']).assign(temp=1), on='temp').drop('temp', axis=1)\n",
    "prod_policies = gp.tuplelist(zip(prod_policies_month_df['FactoryName'], prod_policies_month_df['ProductLine'], \n",
    "                                 prod_policies_month_df['ProductName'], prod_policies_month_df['Period']))\n",
    "factory_lines = list(zip(prod_policies_month_df['FactoryName'], prod_policies_month_df['ProductLine']))\n",
    "\n",
    "inv_basis = gp.tuplelist([(dc, p, m) for dc in dcs for p in products for m in list(months) + [max(months)+1]])\n",
    "\n",
    "### per unit penalty cost of using dummy lanes\n",
    "dmd_pen = np.ceil(max(var_prod_cost.values())*10 + max(var_handling_cost.values())*10 + max(transp_cost.values())*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dc_handling_cap</th>\n",
       "      <th>dc_storage_cap</th>\n",
       "      <th>perc_demand_satisfied</th>\n",
       "      <th>hist_fc</th>\n",
       "      <th>hist_ff</th>\n",
       "      <th>hist_prod</th>\n",
       "      <th>hist_no_prod</th>\n",
       "      <th>fix_factories_open</th>\n",
       "      <th>fix_dcs_open</th>\n",
       "      <th>num_factories_open</th>\n",
       "      <th>num_dcs_open</th>\n",
       "      <th>initial_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline2021</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unconstrainted</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CloseOneFactory</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unconstrainted+RemoveStorageCons</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unconstrainted+RemoveHandlingCons</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   dc_handling_cap  dc_storage_cap  \\\n",
       "Baseline2021                                 False           False   \n",
       "Unconstrainted                                True            True   \n",
       "CloseOneFactory                               True            True   \n",
       "Unconstrainted+RemoveStorageCons              True           False   \n",
       "Unconstrainted+RemoveHandlingCons            False            True   \n",
       "\n",
       "                                   perc_demand_satisfied  hist_fc  hist_ff  \\\n",
       "Baseline2021                                       False     True     True   \n",
       "Unconstrainted                                     False    False    False   \n",
       "CloseOneFactory                                    False    False    False   \n",
       "Unconstrainted+RemoveStorageCons                   False    False    False   \n",
       "Unconstrainted+RemoveHandlingCons                  False    False    False   \n",
       "\n",
       "                                   hist_prod  hist_no_prod  \\\n",
       "Baseline2021                            True          True   \n",
       "Unconstrainted                         False         False   \n",
       "CloseOneFactory                        False         False   \n",
       "Unconstrainted+RemoveStorageCons       False         False   \n",
       "Unconstrainted+RemoveHandlingCons      False         False   \n",
       "\n",
       "                                   fix_factories_open  fix_dcs_open  \\\n",
       "Baseline2021                                     True          True   \n",
       "Unconstrainted                                   True          True   \n",
       "CloseOneFactory                                  True          True   \n",
       "Unconstrainted+RemoveStorageCons                 True          True   \n",
       "Unconstrainted+RemoveHandlingCons                True          True   \n",
       "\n",
       "                                   num_factories_open  num_dcs_open  \\\n",
       "Baseline2021                                        9             9   \n",
       "Unconstrainted                                      9             9   \n",
       "CloseOneFactory                                     8             8   \n",
       "Unconstrainted+RemoveStorageCons                    9             9   \n",
       "Unconstrainted+RemoveHandlingCons                   9             9   \n",
       "\n",
       "                                   initial_inv  \n",
       "Baseline2021                              True  \n",
       "Unconstrainted                            True  \n",
       "CloseOneFactory                           True  \n",
       "Unconstrainted+RemoveStorageCons          True  \n",
       "Unconstrainted+RemoveHandlingCons         True  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scenarios matrix\n",
    "scenario_list = ['Baseline2021','Unconstrainted','CloseOneFactory','Unconstrainted+RemoveStorageCons','Unconstrainted+RemoveHandlingCons']\n",
    "constr_setting = {'dc_handling_cap':[False, True, True, True, False], \n",
    "                  'dc_storage_cap':[False, True, True, False, True],\n",
    "                  'perc_demand_satisfied':[False, False, False, False, False],\n",
    "                  'hist_fc':[True, False, False, False, False], \n",
    "                  'hist_ff':[True, False, False, False, False], \n",
    "                  'hist_prod':[True, False, False, False, False], \n",
    "                  'hist_no_prod':[True, False, False, False, False], \n",
    "                  'fix_factories_open':[True, True, True, True, True],\n",
    "                  'fix_dcs_open':[True, True, True, True, True],\n",
    "                  'num_factories_open':[9, 9, 8, 9, 9], \n",
    "                  'num_dcs_open':[9, 9, 8, 9, 9], \n",
    "                  'initial_inv': [True, True, True, True, True]}\n",
    "scenario_matrix = pd.DataFrame(constr_setting, index=scenario_list)\n",
    "scenario_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Optimization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "today = str(today).replace('-','')\n",
    "\n",
    "#scenario = 'Baseline2021'\n",
    "#scenario = 'Unconstrainted'\n",
    "#scenario = 'CloseOneFactory'\n",
    "#scenario = 'Unconstrainted+RemoveStorageCons'\n",
    "scenario = 'Unconstrainted+RemoveHandlingCons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter CloudAccessID\n",
      "Set parameter CloudSecretKey\n",
      "Set parameter CloudPool to value \"800758-SCORteamCOMMON\"\n",
      "Set parameter CSAppName to value \"SCOR Team Common License\"\n",
      "Set parameter LicenseID\n",
      "Waiting for cloud server to start (pool 800758-SCORteamCOMMON)...\n",
      "Starting...\n",
      "Starting...\n",
      "Starting...\n",
      "Starting...\n",
      "Starting...\n",
      "Compute Server job ID: cd41a018-447f-4327-ae8b-7e9749f4e577\n",
      "Capacity available on '800758-SCORteamCOMMON' cloud pool - connecting...\n",
      "Established HTTPS encrypted connection\n",
      "Gurobi Optimizer version 9.5.1 build v9.5.1rc2 (win64)\n",
      "Gurobi Compute Server Worker version 9.5.1 build v9.5.1rc2 (linux64)\n",
      "Thread count: 16 physical cores, 32 logical processors, using up to 32 threads\n",
      "Optimize a model with 50194 rows, 409841 columns and 800420 nonzeros\n",
      "Model fingerprint: 0x91b9eb4a\n",
      "Variable types: 375708 continuous, 34133 integer (34133 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [3e-03, 2e+05]\n",
      "  Objective range  [1e-01, 3e+07]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [5e-01, 3e+05]\n",
      "Presolve removed 9741 rows and 53223 columns\n",
      "Presolve time: 2.81s\n",
      "Presolved: 40453 rows, 356618 columns, 686000 nonzeros\n",
      "Variable types: 322986 continuous, 33632 integer (33632 binary)\n",
      "\n",
      "Deterministic concurrent LP optimizer: primal and dual simplex\n",
      "Showing first log only...\n",
      "\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "   60447   -5.8502886e+07   1.559475e+04   4.451366e+08      5s\n",
      "   60526    5.9172739e+08   0.000000e+00   6.545915e+06      5s\n",
      "Concurrent spin time: 0.00s\n",
      "\n",
      "Solved with dual simplex\n",
      "\n",
      "Root relaxation: objective 4.501276e+08, 50764 iterations, 1.55 seconds (0.98 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0    4.501276e+08 4.5013e+08  0.00%     -    5s\n",
      "\n",
      "Explored 1 nodes (50764 simplex iterations) in 5.22 seconds (3.09 work units)\n",
      "Thread count was 32 (of 32 available processors)\n",
      "\n",
      "Solution count 1: 4.50128e+08 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.501275963372e+08, best bound 4.501275963372e+08, gap 0.0000%\n",
      "\n",
      "optimal\n",
      "model build time: 89 s\n",
      "model solve time: 11 s\n",
      "total operating cost: 450127596.3372089\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "### create model\n",
    "m = gp.Model('BXNetworkOpt')\n",
    "\n",
    "### decision variables\n",
    "ss_flow = m.addVars(ss_lanes, vtype=gp.GRB.CONTINUOUS, name='ff_flow') # factory to dc flows\n",
    "sc_flow = m.addVars(sc_lanes, vtype=gp.GRB.CONTINUOUS, name='fc_flow') # dc to customer flows\n",
    "prod_flow = m.addVars(prod_policies, vtype=gp.GRB.CONTINUOUS, name='prod_flow') # production volume\n",
    "inv_level = m.addVars(inv_basis, vtype=gp.GRB.CONTINUOUS, name='inv_level') # beginning inventory level of each month\n",
    "f_open = m.addVars(factories, vtype=gp.GRB.BINARY, name='f_open') # factory open or not\n",
    "dc_open = m.addVars(dcs, vtype=gp.GRB.BINARY, name='dc_open') # factory open or not\n",
    "demand_slack = m.addVars(cust_demand, vtype=gp.GRB.BINARY, name='demand_slack') # slack variable for unmatched demand\n",
    "\n",
    "m.update()\n",
    "\n",
    "### objective function\n",
    "tot_var_prod_cost = gp.quicksum(prod_flow[(f, l, p, m)]*var_prod_cost[(f, p)] for (f, l, p, m) in prod_policies)\n",
    "tot_var_handling_cost = gp.quicksum(sc_flow[(o, d, p, m)]*var_handling_cost[(o)] for (o, d, p, m) in sc_lanes) \n",
    "tot_site_fixed_cost = gp.quicksum(f_open[f]*site_fixed_cost[f] for f in factories) + gp.quicksum(dc_open[dc]*site_fixed_cost[dc] for dc in dcs)\n",
    "tot_ss_transp_cost = gp.quicksum(ss_flow[(o, d, p, m)]*product_cubic[p]*transp_cost[(o, d)] for (o, d, p, m) in ss_lanes)\n",
    "tot_sc_transp_cost = gp.quicksum(sc_flow[(o, d, p, m)]*product_cubic[p]*transp_cost[(o, d)] for (o, d, p, m) in sc_lanes)\n",
    "tot_dmd_pen_cost = demand_slack.sum('*', '*', '*')*dmd_pen\n",
    "tot_cost = tot_var_prod_cost + tot_var_handling_cost + tot_site_fixed_cost + tot_ss_transp_cost + tot_sc_transp_cost + tot_dmd_pen_cost\n",
    "\n",
    "m.setObjective(tot_cost, gp.GRB.MINIMIZE)\n",
    "\n",
    "### demand satisfaction\n",
    "m.addConstrs(\n",
    "    (sc_flow.sum('*', c, p, m) == cust_demand[(c, p, m)] + demand_slack[(c, p, m)] for (c, p, m) in cust_demand.keys()), 'customer_demand'\n",
    ")\n",
    "\n",
    "\n",
    "### at least 80% demand must be satisfied\n",
    "if scenario_matrix.loc[scenario, 'perc_demand_satisfied']:\n",
    "    m.addConstr(\n",
    "        (sc_flow.sum('*', '*', '*', '*') >= 0.8 * sum(cust_demand.values())), 'perc_demand_satisfied'\n",
    "    )\n",
    "\n",
    "### flow balance\n",
    "### factory flow balance\n",
    "m.addConstrs(\n",
    "    (ss_flow.sum(f, '*', p, m) == prod_flow.sum(f, '*', p, m) for f in factories for p in products for m in months), 'flow_balance'\n",
    ")\n",
    "### dc flow balance\n",
    "m.addConstrs(\n",
    "    (inv_level[(dc, p, m)] + ss_flow.sum('*', dc, p, m) == sc_flow.sum(dc, '*', p, m) + inv_level[(dc, p, m+1)]\n",
    "     for dc in dcs for p in products for m in months), 'flow_balance'\n",
    ")\n",
    "\n",
    "### factory production capacity by line\n",
    "m.addConstrs(\n",
    "    (gp.quicksum([prod_flow[(f, l, p, m)] * line_product_rate[(f, l, p)] for p in line_product_dict[(f, l)]])<= line_capacity_cap[(f, l)]*f_open[f] for (f, l, p, m) in prod_policies), 'line_capacity_cap'\n",
    ")\n",
    "\n",
    "### dc handling capacity\n",
    "if scenario_matrix.loc[scenario, 'dc_handling_cap']:\n",
    "    m.addConstrs(\n",
    "        (sc_flow.sum(dc, '*', '*', m) \n",
    "         <= site_handling_cap[dc]*dc_open[dc] for dc in dcs for m in months), 'dc_handling_cap'\n",
    "    )\n",
    "\n",
    "### dc storage capacity\n",
    "if scenario_matrix.loc[scenario, 'dc_storage_cap']:\n",
    "    m.addConstrs(\n",
    "        (inv_level.sum(dc, '*', m) \n",
    "         <= site_storage_cap[dc]*dc_open[dc] for dc in dcs for m in months), 'dc_storage_cap'\n",
    "    )\n",
    "\n",
    "### number of factories open\n",
    "if scenario_matrix.loc[scenario, 'fix_factories_open']:\n",
    "    m.addConstr(\n",
    "        (f_open.sum('*') == scenario_matrix.loc[scenario, 'num_factories_open']), 'num_factories_open'\n",
    "    )\n",
    "\n",
    "### number of dcs open\n",
    "if scenario_matrix.loc[scenario, 'fix_dcs_open']:\n",
    "    m.addConstr(\n",
    "        (dc_open.sum('*') == scenario_matrix.loc[scenario, 'num_dcs_open']), 'num_dcs_open'\n",
    "    )\n",
    "\n",
    "### zero inital inventory\n",
    "if scenario_matrix.loc[scenario, 'initial_inv']:\n",
    "    m.addConstrs(\n",
    "        (inv_level[dc, p, 1] == 0 for dc in dcs for p in products), 'intial_inv'\n",
    "    )\n",
    "\n",
    "##########################historical cons\n",
    "### historical factory-to-customer flows\n",
    "if scenario_matrix.loc[scenario, 'hist_fc']:\n",
    "    m.addConstrs(\n",
    "        (sc_flow[(o, d, p, m)] == hist_fc_flows[(o, d, p, m)] for (o, d, p, m) in hist_fc_flows.keys()), 'hist_fc'\n",
    "    )\n",
    "\n",
    "### historical inter-factory flows\n",
    "if scenario_matrix.loc[scenario, 'hist_ff']:\n",
    "    m.addConstrs(\n",
    "        (ss_flow[(o, d, p, m)] == hist_ff_flows[(o, d, p, m)] for (o, d, p, m) in hist_ff_flows.keys()), 'hist_ff'\n",
    "    )\n",
    "\n",
    "### historical production\n",
    "if scenario_matrix.loc[scenario, 'hist_prod']:\n",
    "    m.addConstrs(\n",
    "        (prod_flow[(f, l, p, m)] == hist_prod_flows[(f, l, p, m)] for (f, l, p, m) in hist_prod_flows.keys()), 'hist_prod'\n",
    "    )\n",
    "\n",
    "### historical no production\n",
    "if scenario_matrix.loc[scenario, 'hist_no_prod']:\n",
    "    m.addConstrs(\n",
    "        (prod_flow[(f, l, p, m)] == 0 for (f, l, p, m) in [x for x in prod_policies if x not in hist_prod_flows.keys()]), \n",
    "        'hist_no_prod'\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "time_build_end = time.time()\n",
    "\n",
    "### solve the model\n",
    "m.optimize()\n",
    "time_solve_end = time.time()\n",
    "\n",
    "print()\n",
    "print('optimal' if m.status==gp.GRB.OPTIMAL else 'infeasible')\n",
    "print('model build time:', round(time_build_end - time_start), 's')\n",
    "print('model solve time:', round(time_solve_end - time_build_end), 's')\n",
    "tot_oprt_cost = tot_var_prod_cost.getValue() + tot_var_handling_cost.getValue() + tot_site_fixed_cost.getValue() \\\n",
    "                + tot_sc_transp_cost.getValue() + tot_ss_transp_cost.getValue()\n",
    "print('total operating cost:', tot_oprt_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_flow_res = []\n",
    "\n",
    "for i in sc_lanes:\n",
    "    if sc_flow[i].x > 0:\n",
    "        var_output = {\n",
    "            'Origin': i[0],\n",
    "            'Destination': i[1],\n",
    "            'ProductName': i[2],\n",
    "            'Period': i[3],\n",
    "            'Quantity': sc_flow[i].x\n",
    "        }\n",
    "        sc_flow_res.append(var_output)\n",
    "\n",
    "sc_flow_res_df = pd.DataFrame.from_records(sc_flow_res)\n",
    "\n",
    "len(sc_flow_res_df) == len(hist_outbound_trans_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_flow_res = []\n",
    "\n",
    "for i in ss_lanes:\n",
    "    if ss_flow[i].x > 0:\n",
    "        var_output = {\n",
    "            'Origin': i[0],\n",
    "            'Destination': i[1],\n",
    "            'ProductName': i[2],\n",
    "            'Period': i[3],\n",
    "            'Quantity': ss_flow[i].x\n",
    "        }\n",
    "        ss_flow_res.append(var_output)\n",
    "\n",
    "ss_flow_res_df = pd.DataFrame.from_records(ss_flow_res)\n",
    "\n",
    "len(ss_flow_res_df) == len(hist_inbound_trans_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_flow_res = []\n",
    "\n",
    "for i in prod_policies:\n",
    "    if prod_flow[i].x > 0:\n",
    "        var_output = {\n",
    "            'FactoryName': i[0],\n",
    "            'ProductLine': i[1],\n",
    "            'ProductName': i[2],\n",
    "            'Period': i[3],\n",
    "            'Quantity': prod_flow[i].x\n",
    "        }\n",
    "        prod_flow_res.append(var_output)\n",
    "        \n",
    "prod_flow_res_df = pd.DataFrame.from_records(prod_flow_res)\n",
    "\n",
    "len(prod_flow_res_df) == len(hist_prod_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SiteName</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>Period</th>\n",
       "      <th>Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DC_1</td>\n",
       "      <td>PROD_6</td>\n",
       "      <td>3</td>\n",
       "      <td>2.680000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DC_1</td>\n",
       "      <td>PROD_11</td>\n",
       "      <td>3</td>\n",
       "      <td>9.100000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DC_1</td>\n",
       "      <td>PROD_33</td>\n",
       "      <td>13</td>\n",
       "      <td>3.637979e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DC_1</td>\n",
       "      <td>PROD_34</td>\n",
       "      <td>3</td>\n",
       "      <td>5.059617e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DC_1</td>\n",
       "      <td>PROD_39</td>\n",
       "      <td>9</td>\n",
       "      <td>2.098834e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SiteName ProductName  Period      Quantity\n",
       "0     DC_1      PROD_6       3  2.680000e+02\n",
       "1     DC_1     PROD_11       3  9.100000e+02\n",
       "2     DC_1     PROD_33      13  3.637979e-12\n",
       "3     DC_1     PROD_34       3  5.059617e+04\n",
       "4     DC_1     PROD_39       9  2.098834e+05"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_level_res = []\n",
    "\n",
    "for i in inv_basis:\n",
    "    if inv_level[i].x > 0:\n",
    "        var_output = {\n",
    "            'SiteName': i[0],\n",
    "            'ProductName': i[1],\n",
    "            'Period': i[2],\n",
    "            'Quantity': inv_level[i].x\n",
    "        }\n",
    "        inv_level_res.append(var_output)\n",
    "        \n",
    "inv_level_res_df = pd.DataFrame.from_records(inv_level_res)\n",
    "\n",
    "inv_level_res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no unsatisfied demand\n"
     ]
    }
   ],
   "source": [
    "demand_slack_res = [] \n",
    "\n",
    "for i in cust_demand:\n",
    "    if demand_slack[i].x > 0:\n",
    "        var_output = {\n",
    "            'FactoryName': i[1],\n",
    "            'ProductName': i[2],\n",
    "            'Period': i[3],\n",
    "            'Quantity': demand_slack[i].x\n",
    "        }\n",
    "        demand_slack_res.append(var_output)\n",
    "        \n",
    "demand_slack_res_df = pd.DataFrame.from_records(demand_slack_res)\n",
    "\n",
    "if len(demand_slack_res_df)>1:\n",
    "    print(demand_slack_res_df[['Quantity']].sum())\n",
    "else:\n",
    "    print('no unsatisfied demand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SiteName</th>\n",
       "      <th>SiteStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FAC_1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FAC_2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FAC_3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FAC_4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FAC_5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FAC_6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FAC_7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FAC_8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FAC_9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SiteName  SiteStatus\n",
       "0    FAC_1         1.0\n",
       "1    FAC_2         1.0\n",
       "2    FAC_3         1.0\n",
       "3    FAC_4         1.0\n",
       "4    FAC_5         1.0\n",
       "5    FAC_6         1.0\n",
       "6    FAC_7         1.0\n",
       "7    FAC_8         1.0\n",
       "8    FAC_9         1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_open_res = []\n",
    "\n",
    "for i in factories:\n",
    "    var_output = {\n",
    "        'SiteName': i,\n",
    "        'SiteStatus': f_open[i].x\n",
    "    }\n",
    "    f_open_res.append(var_output)\n",
    "        \n",
    "f_open_res_df = pd.DataFrame.from_records(f_open_res)\n",
    "\n",
    "f_open_res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SiteName</th>\n",
       "      <th>SiteStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DC_1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DC_2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DC_3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DC_4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DC_5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DC_6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DC_7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DC_8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DC_9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SiteName  SiteStatus\n",
       "0     DC_1         1.0\n",
       "1     DC_2         1.0\n",
       "2     DC_3         1.0\n",
       "3     DC_4         1.0\n",
       "4     DC_5         1.0\n",
       "5     DC_6         1.0\n",
       "6     DC_7         1.0\n",
       "7     DC_8         1.0\n",
       "8     DC_9         1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_open_res = []\n",
    "\n",
    "for i in dcs:\n",
    "    var_output = {\n",
    "        'SiteName': i,\n",
    "        'SiteStatus': dc_open[i].x\n",
    "    }\n",
    "    dc_open_res.append(var_output)\n",
    "        \n",
    "dc_open_res_df = pd.DataFrame.from_records(dc_open_res)\n",
    "\n",
    "dc_open_res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare output tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "### add cost of flow and production\n",
    "sc_flow_res_df_1 = sc_flow_res_df.merge(trans_policies_df, on = ['Origin','Destination'])\\\n",
    "    .merge(products_df[['ProductName','Volume']], on = ['ProductName'])\\\n",
    "        .assign(**{\"TransportationCost\": lambda x: x['Quantity']*x['Volume']*x['Price']})\\\n",
    "            .merge(var_handling_cost_df.rename({'SiteName':'Origin'},axis=1), on = ['Origin'])\\\n",
    "                .assign(**{\"HandlingCost\": lambda x: x['Quantity']*x['VariableCost']})\n",
    "\n",
    "\n",
    "ss_flow_res_df_1 = ss_flow_res_df.merge(trans_policies_df, on = ['Origin','Destination'])\\\n",
    "    .merge(products_df[['ProductName','Volume']], on = ['ProductName'])\\\n",
    "        .assign(**{\"TransportationCost\": lambda x: x['Quantity']*x['Volume']*x['Price']})\n",
    "\n",
    "prod_flow_res_df_1 = prod_flow_res_df.merge(var_prod_cost_df, on = ['FactoryName','ProductName'])\\\n",
    "    .assign(**{\"ProductionCost\": lambda x: x['Quantity']*x['VariableCost']})\\\n",
    "        .merge(prod_policies_df, on = ['FactoryName','ProductLine','ProductName'])\\\n",
    "            .assign(**{'MachineHours': lambda x: x['Quantity'] * x['MachineHoursPerUnit']})\n",
    "\n",
    "site_open_res_df_1 = site_fixed_cost_df.merge(pd.concat([f_open_res_df,dc_open_res_df]), on = 'SiteName', how= 'left')\\\n",
    "    .assign(**{'SiteFixedOperatingCost': lambda x: x['SiteStatus']*x['FixedOperatingCost']})\n",
    "\n",
    "### period cost summary \n",
    "period_cost_summary = sc_flow_res_df_1.groupby(['Period'])[['TransportationCost','HandlingCost','Quantity']].sum().reset_index()\\\n",
    "    .rename({'TransportationCost':'TransportationCostCustomerFlows','HandlingCost':'DCHandlingCost','Quantity':'QuantityCustomerFlows'},axis=1)\\\n",
    "        .merge(ss_flow_res_df_1.groupby(['Period'])[['TransportationCost','Quantity']].sum().reset_index()\\\n",
    "            .rename({'TransportationCost':'TransportationCostIntersiteFlows','Quantity':'QuantityIntersiteFlows'},axis=1), on = ['Period'])\\\n",
    "                .assign(**{'TransportationCost': lambda x: (x['TransportationCostCustomerFlows']+x['TransportationCostIntersiteFlows'])})\\\n",
    "                    .merge(prod_flow_res_df_1.groupby(['Period'])[['ProductionCost','Quantity','MachineHours']].sum().reset_index()\\\n",
    "                        .rename({'ProductionCost':'FactoryProductionCost', 'Quantity':'FactoryProductionQuantity'},axis=1), on = ['Period'])\\\n",
    "                            .assign(SiteFixedOperatingCost = site_open_res_df_1[['FixedOperatingCost']].sum()[0]/12, \n",
    "                                    NumberOfSitesOpen = site_open_res_df_1[['SiteStatus']].sum()[0])\\\n",
    "                                        .assign(TotalCost = lambda x: x['TransportationCost']+x['DCHandlingCost']+x['FactoryProductionCost']+x['SiteFixedOperatingCost'])\n",
    "                                            # .assign(ProductionCapacityUtilization = lambda x: x['MachineHours']/prod_line_policies_df['MachineHourCapacity'].sum(),\n",
    "                                            #         HandlingCapacityUtilization = lambda x: x['QuantityCustomerFlows']/sites_df['HandlingCapacity'].sum(),\n",
    "                                            #         ### use inventory turns to calculate monthly storage utilization, is it ok?\n",
    "                                            #         StorageCapacityUtilization = lambda x: x['QuantityCustomerFlows']/(inv_df['InventoryTurns'].mean()/12*sites_df['StorageCapacity'].sum()))\n",
    "  \n",
    "### site cost summary\n",
    "##### factory cost summary\n",
    "factory_cost_summary = ss_flow_res_df_1.groupby(['Origin']).apply(lambda x : pd.Series({\n",
    "                                                                                        'TransportationCost': x['TransportationCost'].sum(),\n",
    "                                                                                        'Quantity': x['Quantity'].sum(),\n",
    "                                                                                        'MaxDistance':x['Distance'].max(),\n",
    "                                                                                        'WeightedAverageDistance':(x['Quantity']*x['Volume']*x['Distance']).sum() / (x['Quantity']*x['Volume']).sum(),\n",
    "                                                                                        })).reset_index()\\\n",
    "            .rename({'Origin':'SiteName', 'TransportationCost':'OutboundTransportationCost', 'Quantity':'ThoughputLevel'},axis=1)\\\n",
    "                .merge(prod_flow_res_df_1.groupby(['FactoryName'])[['ProductionCost','MachineHours']].sum().reset_index()\\\n",
    "                    .merge(prod_line_policies_df.groupby(['FactoryName']).agg({'MachineHourCapacity':'sum'}).reset_index(), on = ['FactoryName'])\\\n",
    "                        .assign(MachineHourCapacity = lambda x: x['MachineHourCapacity']*12,\n",
    "                                ProductionCapacityUtilization = lambda x: x['MachineHours']/x['MachineHourCapacity'])\\\n",
    "                            .rename({'FactoryName':'SiteName'},axis=1), on = 'SiteName')\n",
    "factory_cost_summary.insert(1, 'SiteType', 'Factory')\n",
    "##### dc cost summary\n",
    "dc_cost_summary = sc_flow_res_df_1.groupby(['Origin']).apply(lambda x : pd.Series({'TransportationCost': x['TransportationCost'].sum(),\n",
    "                                                                                    'HandlingCost': x['HandlingCost'].sum(),\n",
    "                                                                                    'Quantity': x['Quantity'].sum(),\n",
    "                                                                                    'MaxDistance':x['Distance'].max(),\n",
    "                                                                                    'WeightedAverageDistance':(x['Quantity']*x['Volume']*x['Distance']).sum() / (x['Quantity']*x['Volume']).sum(),\n",
    "                                                                                    })).reset_index()\\\n",
    "     .rename({'Origin':'SiteName', 'TransportationCost':'OutboundTransportationCost', 'Quantity':'ThoughputLevel'},axis=1)\\\n",
    "        .merge(sites_df[['SiteName','StorageCapacity','HandlingCapacity']], on = ['SiteName'])\\\n",
    "            .assign(HandlingCapacity = lambda x: x['HandlingCapacity']*12)\\\n",
    "                .merge(inv_df, on = ['SiteName'])\\\n",
    "                     .assign(HandlingCapacityUtilization = lambda x: x['ThoughputLevel']/x['HandlingCapacity'],\n",
    "                             StorageCapacityUtilization = lambda x: x['ThoughputLevel']/(x['InventoryTurns']*x['StorageCapacity']))\\\n",
    "                                .drop(['InventoryTurns'],axis=1)\n",
    "dc_cost_summary.insert(1, 'SiteType', 'Distribution Center')\n",
    "site_cost_summary = pd.concat([factory_cost_summary, dc_cost_summary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################(discard)\n",
    "# ### dc to customer transportation cost\n",
    "# sc_trans_cost_sum_df = sc_flow_res_df.merge(trans_policies_df, on = ['Origin','Destination'])\\\n",
    "#     .merge(products_df, on = ['ProductName'])\\\n",
    "#         .assign(**{\"TransportationCost\": lambda x: x['Quantity']*x['Volume']*x['Price']})\\\n",
    "#             .groupby(['Origin','ProductName','Period'])\\\n",
    "#                 .agg({'TransportationCost':'sum','Quantity':'sum'}).reset_index()\\\n",
    "#                     .rename({'Origin':'FactoryName'},axis=1)\n",
    "\n",
    "# ### factory to dc transportation cost\n",
    "# if ss_flow_res_df.shape[0] != 0:\n",
    "#     ss_trans_cost_sum_df = ss_flow_res_df.merge(trans_policies_df, on = ['Origin','Destination'])\\\n",
    "#         .merge(products_df, on = ['ProductName'])\\\n",
    "#             .assign(**{\"TransportationCost\": lambda x: x['Quantity']*x['Volume']*x['Price']})\\\n",
    "#                  .groupby(['Destination','ProductName','Period'])\\\n",
    "#                     .agg({'TransportationCost':'sum','Quantity':'sum'}).reset_index()\\\n",
    "#                         .rename({'Destination':'FactoryName'},axis=1)\n",
    "# else:\n",
    "#     ff_trans_cost_sum_df = pd.DataFrame(columns=['FactoryName','Period','TransportationCost','Quantity'])\n",
    "\n",
    "# ### factory variable cost\n",
    "# factory_var_cost_sum_df = prod_flow_res_df.merge(factory_var_cost_df, on = ['FactoryName','ProductName'])\\\n",
    "#     .assign(**{\"FactoryVariableCost\": lambda x: x['Quantity']*x['VariableCost']})\\\n",
    "#         .merge(prod_policies_df, on = ['FactoryName','ProductLine','ProductName'])\\\n",
    "#             .assign(**{'MachineHours': lambda x: x['Quantity'] * x['MachineHoursPerUnit']})\\\n",
    "#                 .groupby(['FactoryName','ProductName','Period'])\\\n",
    "#                     .agg({'FactoryVariableCost':'sum','Quantity':'sum','MachineHours':'sum'}).reset_index()\\\n",
    "#                         .rename({'Quantity':'ProductionQuantity'},axis=1)\n",
    "\n",
    "# ### factory fixed cost\n",
    "# factory_fixed_cost_sum_df = pd.merge(f_open_res_df, factory_fixed_cost_df, on = 'FactoryName').assign(**{'FactoryFixedOperatingCost': lambda x: x['FactoryStatus']*x['FixedOperatingCost']})\n",
    "\n",
    "# ### factory level cost summary\n",
    "# factory_cost_sum_df = fc_trans_cost_sum_df.groupby(['FactoryName'])[['TransportationCostFactoryToCustomer', 'QuantityFactoryToCustomer']].sum().reset_index()\\\n",
    "#     .merge(ff_trans_cost_sum_df.groupby(['FactoryName'])[['TransportationCostAmongFactoryInflow','QuantityAmongFactoryInflow']].sum().reset_index(), on = ['FactoryName'], how = 'left').fillna(0)\\\n",
    "#         .merge(ff_flow_res_df.groupby(['Origin']).agg({'Quantity':'sum'}).reset_index().rename({'Origin':'FactoryName', 'Quantity':'QuantityAmongFactoryOutflow'},axis=1), on = ['FactoryName'], how = 'left').fillna(0)\\\n",
    "#             .merge(factory_var_cost_sum_df.groupby(['FactoryName'])[['FactoryVariableCost','ProductionQuantity','MachineHours']].sum().reset_index(), on = ['FactoryName'])\\\n",
    "#                 .merge(factory_fixed_cost_sum_df[['FactoryName','FactoryFixedOperatingCost']], on = ['FactoryName'])\\\n",
    "#                     .merge(factories_df[['FactoryName','StorageCapacity','HandlingCapacity']].assign(HandlingCapacity = lambda x: x['HandlingCapacity']*12).rename({'HandlingCapacity':'AnnualHandlingCapacity'},axis=1), on = ['FactoryName'])\\\n",
    "#                         .merge(inv_df[['FactoryName','InventoryTurns']].rename({'InventoryTurns':'AnnualInventoryTurns'},axis=1), on = ['FactoryName'])\\\n",
    "#                             .merge(prod_line_policies_df.groupby(['FactoryName']).agg(MachineHourCapacity = ('MachineHourCapacity', lambda x: x.sum() * 12)).reset_index().rename({'MachineHourCapacity':'AnnualMachineHourCapacity'},axis=1), on = ['FactoryName'])\\\n",
    "#                                 .assign(**{'HandlingCapacityUtilization': lambda x: (x['QuantityFactoryToCustomer']+x['QuantityAmongFactoryOutflow'])/x['AnnualHandlingCapacity']})\\\n",
    "#                                     .assign(**{'StorageCapacityUtilization': lambda x: (x['QuantityFactoryToCustomer']+x['QuantityAmongFactoryOutflow'])/(x['AnnualInventoryTurns']*x['StorageCapacity'])})\\\n",
    "#                                         .assign(**{'ProductionCapacityUtilization': lambda x: x['MachineHours']/x['AnnualMachineHourCapacity']})\\\n",
    "#                                             .assign(**{'TransportationQuantityOutflow': lambda x: (x['QuantityFactoryToCustomer']+x['QuantityAmongFactoryOutflow'])})\\\n",
    "#                                                 .assign(**{'TransportationCost': lambda x: (x['TransportationCostFactoryToCustomer']+x['TransportationCostAmongFactoryInflow'])})\n",
    "\n",
    "# ### factory + month level cost summary\n",
    "# factory_cost_monthly_sum_df = fc_trans_cost_sum_df.groupby(['FactoryName','Period'])[['TransportationCostFactoryToCustomer', 'QuantityFactoryToCustomer']].sum().reset_index()\\\n",
    "#     .merge(ff_trans_cost_sum_df.groupby(['FactoryName','Period'])[['TransportationCostAmongFactoryInflow','QuantityAmongFactoryInflow']].sum().reset_index(), on = ['FactoryName','Period'], how = 'outer')\\\n",
    "#         .merge(ff_flow_res_df.groupby(['Origin','Period']).agg({'Quantity':'sum'}).reset_index().rename({'Origin':'FactoryName', 'Quantity':'QuantityAmongFactoryOutflow'},axis=1), on = ['FactoryName','Period'], how = 'left').fillna(0)\\\n",
    "#             .merge(factory_var_cost_sum_df.groupby(['FactoryName','Period'])[['FactoryVariableCost','ProductionQuantity','MachineHours']].sum().reset_index(), on = ['FactoryName','Period'], how = 'outer')\\\n",
    "#                 .merge(factory_fixed_cost_sum_df[['FactoryName','FactoryFixedOperatingCost']].assign(**{'FactoryFixedOperatingCost':lambda x: x['FactoryFixedOperatingCost']/12}), on = ['FactoryName'], how = 'outer').fillna(0)\\\n",
    "#                     .merge(factories_df[['FactoryName','StorageCapacity','HandlingCapacity']].rename({'HandlingCapacity':'MonthlyHandlingCapacity'},axis=1), on = ['FactoryName'])\\\n",
    "#                         .merge(inv_df[['FactoryName','InventoryTurns']].assign(**{'MonthlyInventoryTurns': lambda x: x['InventoryTurns']/12}).drop(['InventoryTurns'],axis=1), on = ['FactoryName'])\\\n",
    "#                             .merge(prod_line_policies_df.groupby(['FactoryName']).agg({'MachineHourCapacity':'sum'}).reset_index().rename({'MachineHourCapacity':'MonthlyMachineHourCapacity'},axis=1), on = ['FactoryName'])\\\n",
    "#                                 .assign(**{'HandlingCapacityUtilization': lambda x: (x['QuantityFactoryToCustomer']+x['QuantityAmongFactoryOutflow'])/x['MonthlyHandlingCapacity']})\\\n",
    "#                                     .assign(**{'StorageCapacityUtilization': lambda x: (x['QuantityFactoryToCustomer']+x['QuantityAmongFactoryOutflow'])/(x['MonthlyInventoryTurns']*x['StorageCapacity'])})\\\n",
    "#                                         .assign(**{'ProductionCapacityUtilization': lambda x: x['MachineHours']/x['MonthlyMachineHourCapacity']})\\\n",
    "#                                             .assign(**{'TransportationQuantityOutflow': lambda x: (x['QuantityFactoryToCustomer']+x['QuantityAmongFactoryOutflow'])})\\\n",
    "#                                                     .assign(**{'TransportationCost': lambda x: (x['TransportationCostFactoryToCustomer']+x['TransportationCostAmongFactoryInflow'])})\n",
    "                                                        \n",
    "# factory_cost_monthly_sum_df['EndOfMonthInventory'] = factory_cost_monthly_sum_df.assign(**{'EndOfMonthInventory': lambda x: (x['ProductionQuantity']+x['QuantityAmongFactoryInflow']-x['QuantityAmongFactoryOutflow'])})\\\n",
    "#     .sort_values(['FactoryName','Period']).groupby(['FactoryName'])['EndOfMonthInventory'].cumsum()\n",
    "# factory_cost_monthly_sum_df['StartOfMonthInventory'] = factory_cost_monthly_sum_df['EndOfMonthInventory'].shift(1).fillna(0)\n",
    "\n",
    "\n",
    "# ### service level info\n",
    "# service_level_df = pd.merge(sc_flow_res_df_1.groupby(['Origin','Period'])\\\n",
    "#             .apply(lambda x : pd.Series({'MaxDistanceFactoryToCustomer':x['Distance'].max(),\n",
    "#             'WeightedAverageDistanceCustomerFlows':(x['Quantity']*x['Volume']*x['Distance']).sum() / (x['Quantity']*x['Volume']).sum(),\n",
    "#             })).reset_index().rename({'Origin':'FactoryName'}, axis=1),\n",
    "#         ss_flow_res_df_1.groupby(['Destination','Period'])\\\n",
    "#             .apply(lambda x : pd.Series({\n",
    "#             'WeightedAverageDistanceAmongFactoryInflow':(x['Quantity']*x['Volume']*x['Distance']).sum() / (x['Quantity']*x['Volume']).sum(),\n",
    "#             })).reset_index().rename({'Destination':'FactoryName'}, axis=1),\n",
    "#         on = ['FactoryName','Period'],\n",
    "#         how = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\52427\\.conda\\envs\\gurobienv\\lib\\site-packages\\xlsxwriter\\workbook.py:339: UserWarning: Calling close() on already closed file.\n",
      "  warn(\"Calling close() on already closed file.\")\n"
     ]
    }
   ],
   "source": [
    "### save model output template\n",
    "writer = pd.ExcelWriter(model_sanitized_path + 'model_output_'+ today +'_'+scenario+'.xlsx', engine='xlsxwriter')\n",
    "\n",
    "### output data tables\n",
    "pd.DataFrame({'Scenario': [scenario],\n",
    "                'TotalCost':[tot_var_prod_cost.getValue()+tot_var_handling_cost.getValue()+tot_site_fixed_cost.getValue()+tot_sc_transp_cost.getValue()+tot_ss_transp_cost.getValue()],\n",
    "                'FactoryVariableProductionCost':[tot_var_prod_cost.getValue()],\n",
    "                'DCVariableHandlingCost':[tot_var_handling_cost.getValue()],\n",
    "                'SiteFixedOperatingCost':[tot_site_fixed_cost.getValue()],\n",
    "                'TransportationCost':[tot_sc_transp_cost.getValue()+tot_ss_transp_cost.getValue()],\n",
    "                'TransportationCostCustomerFlows':[tot_sc_transp_cost.getValue()],\n",
    "                'TransportationCostIntersiteFlows':[tot_ss_transp_cost.getValue()],\n",
    "                'DemandSatisfiedPerc': [sc_flow_res_df_1['Quantity'].sum() / demand_df['CustomerDemand'].sum()],\n",
    "                'TotalDemand':[demand_df['CustomerDemand'].sum()],\n",
    "                'QuantityCustomerFlows':[sc_flow_res_df_1['Quantity'].sum()],\n",
    "                'QuantityIntersiteFlows':[ss_flow_res_df_1['Quantity'].sum()],\n",
    "                'MaxDistanceCustomerFlows':[sc_flow_res_df_1['Distance'].max()],\n",
    "                'WeightedAverageDistanceCustomerFlows':[(sc_flow_res_df_1['Quantity']*sc_flow_res_df_1['Volume']*sc_flow_res_df_1['Distance']).sum() / (sc_flow_res_df_1['Quantity']*sc_flow_res_df_1['Volume']).sum()],\n",
    "                'WeightedAverageDistanceIntersiteFlows':[(ss_flow_res_df_1['Quantity']*ss_flow_res_df_1['Volume']*ss_flow_res_df_1['Distance']).sum() / (ss_flow_res_df_1['Quantity']*ss_flow_res_df_1['Volume']).sum()]\n",
    "                })\\\n",
    "        .to_excel(writer, sheet_name='Output_CostSummary', index=False)\n",
    "period_cost_summary.insert(0, 'Scenario', scenario)\n",
    "period_cost_summary.to_excel(writer, sheet_name='Output_CostSummaryByPeriod', index=False)\n",
    "site_cost_summary.insert(0, 'Scenario', scenario)\n",
    "site_cost_summary.to_excel(writer, sheet_name='Output_CostSummaryBySite', index=False)\n",
    "        \n",
    "sc_flow_res_df_1.assign(**{'Scenario': scenario})[['Scenario','Origin','Destination','ProductName','Period','Quantity','TransportationCost','HandlingCost']].to_excel(writer, sheet_name='Output_CustomerFlows', index=False)\n",
    "ss_flow_res_df_1.assign(**{'Scenario': scenario})[['Scenario','Origin','Destination','ProductName','Period','Quantity','TransportationCost']].to_excel(writer, sheet_name='Output_IntersiteFlows', index=False)\n",
    "prod_flow_res_df_1.assign(**{'Scenario': scenario})[['Scenario','FactoryName', 'ProductLine', 'ProductName', 'Period', 'Quantity', 'ProductionCost']].to_excel(writer, sheet_name='Output_ProductionFlows', index=False)\n",
    "\n",
    "inv_level_res_df.assign(**{'Scenario': scenario})[['Scenario','SiteName','ProductName','Period','Quantity']].to_excel(writer, sheet_name='Output_InventoryLevel', index=False)\n",
    "\n",
    "### need further cleaning format before send to client\n",
    "### input data tables\n",
    "products_df.to_excel(writer, sheet_name='Input_ProductList', index=False)\n",
    "customers_df.to_excel(writer, sheet_name='Input_CustomerList', index=False)\n",
    "sites_df.to_excel(writer, sheet_name='Input_FactoryList', index=False)\n",
    "var_prod_cost_df.to_excel(writer, sheet_name='Input_FactoryVariableCost', index=False)\n",
    "site_fixed_cost_df.to_excel(writer, sheet_name='Input_FactoryFixedCost', index=False)\n",
    "trans_policies_df.to_excel(writer, sheet_name='Input_TransportationPolicy', index=False)\n",
    "prod_policies_df.to_excel(writer, sheet_name='Input_CapacityByLineByProduct', index=False)\n",
    "prod_line_policies_df.to_excel(writer, sheet_name='Input_CapacityByLine', index=False)\n",
    "inv_df.to_excel(writer, sheet_name='Input_InventoryPolicy', index=False)\n",
    "demand_df.to_excel(writer, sheet_name='Input_CustomerDemand', index=False)\n",
    "hist_outbound_trans_df.to_excel(writer, sheet_name='Input_HistShipmentFactoryToCust', index=False)\n",
    "hist_inbound_trans_df.to_excel(writer, sheet_name='Input_HistShipmentAmongFactory', index=False)\n",
    "hist_prod_df.to_excel(writer, sheet_name='Input_HistProduction', index=False)\n",
    "\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1655295201.3283813"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('gurobienv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "18e91175e1516bff4eef934baab7668e39e52ce0c83f1a8b750e9bc89fc9161f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
